{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd19df7",
   "metadata": {
    "id": "1cd19df7"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d5789",
   "metadata": {
    "id": "2d7d5789"
   },
   "source": [
    "The primary objective of this project is to develop a robust three-class(Positive, Negative, Neutral) sentiment classification system for social media text and subsequently analyze the quantitative impact of the classified sentiment on post engagement metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c81b78d",
   "metadata": {
    "id": "4c81b78d"
   },
   "source": [
    "## Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1fde5",
   "metadata": {
    "id": "77c1fde5"
   },
   "source": [
    "This study aims to answer the two following questions:\n",
    "* Can a fine-tuned Transformer model accurately and reliably classify social media text into Positive, Neutral, and Negative Sentiments?\n",
    "* Is there a statistically significant relationship between the sentiment expressed in a post and its subsequent level of user engagement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9866e9",
   "metadata": {
    "id": "4b9866e9"
   },
   "source": [
    "The outcomes of this analysis provide not only a highly accurate classification tool but also actionable insights into how sentiment directly influences digital content performance and audience interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a76600d",
   "metadata": {
    "id": "5a76600d"
   },
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2275d",
   "metadata": {
    "id": "10e2275d"
   },
   "source": [
    "We fine-tuned DistilBERT-base-uncased, a pretrained transformer language model derived from BERT using knowledge distillation, for a 3-class sentiment classification task (positive, neutral, negative). The model was trained using labeled social-media post text and optimized via cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a56f4b",
   "metadata": {
    "id": "b5a56f4b"
   },
   "source": [
    "##### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a55f9",
   "metadata": {
    "id": "f85a55f9"
   },
   "outputs": [],
   "source": [
    "#Installing transformers library\n",
    "!pip install -q transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be60c43",
   "metadata": {
    "id": "0be60c43"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, TrainingArguments, Trainer\n",
    ")\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972aba1",
   "metadata": {
    "id": "7972aba1"
   },
   "source": [
    "To import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bae9a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f4bae9a9",
    "outputId": "cfa55c11-db57-4456-c932-663e5a04a058"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Jimmynam0103/Hashtag_Engagement/refs/heads/main/data/sentimentdataset.csv')\n",
    "df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf6665",
   "metadata": {
    "id": "cfbf6665"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822fdb1",
   "metadata": {
    "id": "b822fdb1"
   },
   "source": [
    "The data was analyzed to ensure that there were no missing 'NA' values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c28a20",
   "metadata": {
    "id": "64c28a20"
   },
   "source": [
    "To perform further cleaning & analysis of dataset - the following steps are taken:\n",
    "- Ensuring our sentiments have consistent cases across all records,\n",
    "- Filter the columns that are required in the analysis.\n",
    "- View distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c37f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155c37f7",
    "outputId": "a1c56fe1-5bca-4cc5-be04-135255ac6fb3"
   },
   "outputs": [],
   "source": [
    "df_train = df[[\"Text\", \"Sentiment\", \"Likes\", \"Retweets\"]].copy()\n",
    "df_train.rename(columns={\"Text\": \"text\", \"Sentiment\": \"sentiment\", \"Likes\": \"likes\", \"Retweets\": \"retweets\"}, inplace=True)\n",
    "# Ensure the sentiment column is lowercased\n",
    "df_train[\"sentiment\"] = df_train[\"sentiment\"].str.lower().str.strip()\n",
    "\n",
    "# Check distribution\n",
    "print(df_train[\"sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077b034",
   "metadata": {
    "id": "7077b034"
   },
   "source": [
    "From the distribution of sentiments in our dataset, it is evident that the classes are highly imbalanced. Several sentiment categories, such as lostlove and bittersweet, contain only a single post. With such limited representation, the model does not have sufficient examples to learn meaningful patterns for those classes, making training unreliable. This imbalance also creates challenges when splitting the data into training, validation, and test sets, as minority classes may be completely absent from one of the sets, further reducing model performance and generalizability.\n",
    "\n",
    "To address this issue, we grouped the original fine-grained sentiment labels into three broader categories—positive, neutral, and negative—to ensure more balanced class distributions and improve the effectiveness of model training and evaluation.\n",
    "\n",
    "Note: The grouping of sentiments into the three categories was based on how a typical listener would interpret them—specifically, whether the expressed sentiment would generally be perceived as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8411c2e",
   "metadata": {
    "id": "b8411c2e"
   },
   "source": [
    "#### Define Groupings for Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d0386",
   "metadata": {
    "id": "b71d0386"
   },
   "source": [
    "##### To create a mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2355c0",
   "metadata": {
    "id": "4f2355c0"
   },
   "outputs": [],
   "source": [
    "positive = [\n",
    "    \"positive\",\"happiness\",\"joy\",\"love\",\"amusement\",\"enjoyment\",\"admiration\",\n",
    "    \"affection\",\"awe\",\"surprise\",\"acceptance\",\"adoration\",\"anticipation\",\n",
    "    \"calmness\",\"excitement\",\"kind\",\"pride\",\"elation\",\"euphoria\",\"contentment\",\n",
    "    \"serenity\",\"gratitude\",\"hope\",\"empowerment\",\"compassion\",\"tenderness\",\n",
    "    \"arousal\",\"enthusiasm\",\"fulfillment\",\"reverence\",\"zest\",\"hopeful\",\n",
    "    \"proud\",\"grateful\",\"empathetic\",\"compassionate\",\"playful\",\"free-spirited\",\n",
    "    \"inspired\",\"confident\",\"thrill\",\"overjoyed\",\"inspiration\",\"motivation\",\"satisfaction\",\"blessed\",\"reflection\",\"appreciation\",\n",
    "    \"confidence\",\"accomplishment\",\"wonderment\",\"optimism\",\"enchantment\",\n",
    "    \"intrigue\",\"playfuljoy\",\"mindfulness\",\"elegance\",\"whimsy\",\"pensive\",\n",
    "    \"harmony\",\"creativity\",\"radiance\",\"wonder\",\"rejuvenation\",\"coziness\",\n",
    "    \"adventure\",\"melodic\",\"festivejoy\",\"innerjourney\",\"freedom\",\"dazzle\",\n",
    "    \"adrenaline\",\"artisticburst\",\"culinaryodyssey\",\"resilience\",\"immersion\",\n",
    "    \"spark\",\"marvel\",\"positivity\",\"kindness\",\"friendship\",\"success\",\n",
    "    \"exploration\",\"amazement\",\"romance\",\"captivation\",\"tranquility\",\"grandeur\",\n",
    "    \"energy\",\"celebration\",\"charm\",\"ecstasy\",\"colorful\",\"hypnotic\",\"connection\",\n",
    "    \"iconic\",\"journey\",\"engagement\",\"touched\",\"triumph\",\"heartwarming\",\"solace\",\n",
    "    \"breakthrough\",\"joy in baking\",\"envisioning history\",\"imagination\",\n",
    "    \"vibrancy\",\"mesmerizing\",\"culinary adventure\",\"winter magic\",\n",
    "    \"thrilling journey\",\"nature's beauty\",\"celestial wonder\",\n",
    "    \"creative inspiration\",\"runway creativity\",\"ocean's freedom\",\n",
    "    \"whispers of the past\",\"relief\",\"happy\", \"determination\", \"yearning\", \"joyfulreunion\",\n",
    "    \"dreamchaser\", \"mischievous\"\n",
    "]\n",
    "\n",
    "neutral = [\n",
    "    \"neutral\",\"indifference\",\"numbness\",\"nostalgia\",\n",
    "    \"ambivalence\",\"curiosity\",\"emotion\", \"suspense\", \"contemplation\",\n",
    "]\n",
    "\n",
    "negative = [\n",
    "    \"negative\",\"anger\",\"fear\",\"sadness\",\"disgust\",\"disappointed\",\"bitter\",\n",
    "    \"shame\",\"bitterness\",\"despair\",\"grief\",\"loneliness\",\"jealousy\",\n",
    "    \"resentment\",\"frustration\",\"boredom\",\"anxiety\",\"intimidation\",\n",
    "    \"helplessness\",\"envy\",\"regret\",\"fearful\",\"apprehensive\",\"overwhelmed\",\n",
    "    \"jealous\",\"devastated\",\"frustrated\",\"envious\",\"dismissive\",\"bittersweet\",\n",
    "    \"heartbreak\",\"betrayal\",\"suffering\",\"isolation\",\"disappointment\",\n",
    "    \"lostlove\",\"exhaustion\",\"sorrow\",\"darkness\",\"desperation\",\"ruins\",\n",
    "    \"desolation\",\"loss\",\"heartache\",\"solitude\",\"obstacle\",\"sympathy\",\n",
    "    \"pressure\",\"renewed effort\",\"miscalculation\",\"challenge\",\"sad\",\"hate\",\"bad\",\"embarrassed\",\"emotionalstorm\",\"confusion\",\"melancholy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a9797",
   "metadata": {
    "id": "ed9a9797"
   },
   "source": [
    "#### To build a sentiment map function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5478f",
   "metadata": {
    "id": "a1e5478f"
   },
   "outputs": [],
   "source": [
    "sentiment_map = {}\n",
    "\n",
    "for s in positive:\n",
    "    sentiment_map[s] = \"positive\"\n",
    "for s in neutral:\n",
    "    sentiment_map[s] = \"neutral\"\n",
    "for s in negative:\n",
    "    sentiment_map[s] = \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84552c",
   "metadata": {
    "id": "ce84552c"
   },
   "source": [
    "##### Apply Sentiment Mapping to the DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0546213",
   "metadata": {
    "id": "f0546213"
   },
   "source": [
    "The sentiment mapping is applied to each sentiment to ensure that if it becomes either Positive, Negative or Neutral if it meets the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e7b6c",
   "metadata": {
    "id": "e77e7b6c"
   },
   "outputs": [],
   "source": [
    "df_train[\"sentiment_grouped\"] = df_train[\"sentiment\"].str.lower().str.strip().map(sentiment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3aa58a",
   "metadata": {
    "id": "5b3aa58a"
   },
   "source": [
    "#### Removing Ambiguous Sentiment Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc22bae",
   "metadata": {
    "id": "cbc22bae"
   },
   "source": [
    "Initial modeling revealed that some sentiment labels, particularly those assigned as neutral, were ambiguous. If left unaddressed, these ambiguous labels could negatively impact the accuracy of our sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e353ca1",
   "metadata": {
    "id": "2e353ca1"
   },
   "outputs": [],
   "source": [
    "ambiguous_keywords = [\n",
    "    'melancholy', 'melancholic',\n",
    "    'confusion', 'confused',\n",
    "    'lost',\n",
    "    'emotional storm', 'emotionalstorm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vmK8g-XS8NeK",
   "metadata": {
    "id": "vmK8g-XS8NeK"
   },
   "source": [
    "#### Create a list of ambiguous sentiment to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfcce7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4cfcce7",
    "outputId": "2fc83d80-d865-4a7a-ff2a-a693e6a9268a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of ambiguous sentiment labels to remove\n",
    "ambiguous_sentiments = [\n",
    "    'melancholy', 'melancholic',\n",
    "    'confusion', 'confused',\n",
    "    'lost',\n",
    "    'emotional storm', 'emotionalstorm'\n",
    "]\n",
    "\n",
    "# Remove rows where sentiment value is one of the ambiguous terms\n",
    "df_train = df_train[~df_train['sentiment'].str.lower().isin(ambiguous_sentiments)].copy()\n",
    "\n",
    "print(\"Before:\", len(df))\n",
    "print(\"After:\", len(df_train))\n",
    "print(\"Removed:\", len(df) - len(df_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bedd3d",
   "metadata": {
    "id": "24bedd3d"
   },
   "source": [
    "A total of 33 ambiguous entries were identified and removed from the dataset to improve labeling clarity and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a922e38",
   "metadata": {
    "id": "6a922e38"
   },
   "source": [
    "Note: Initial evaluation revealed reduced accuracy in neutral sentiment classification due to ambiguity in several labels (examples below). By identifying and removing these ambiguous entries before retraining, we can achieve improved model performance and more distinct sentiment class boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29e947",
   "metadata": {
    "id": "cb29e947"
   },
   "source": [
    "#### Create a numeric label for model training and confirm all sentiments correctly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb86e57",
   "metadata": {
    "id": "ccb86e57"
   },
   "source": [
    "Assigning numeric labels to the sentiment categories allows the machine learning model to process and learn from them. Since most models cannot directly interpret text-based labels (such as “positive,” “neutral,” and “negative”), converting them into numeric form (e.g., 0, 1, 2) enables efficient computation, proper encoding of class membership, and compatibility with model algorithms and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45dbf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad45dbf1",
    "outputId": "92c4d7a6-6e70-48cb-d246-2345dd018061"
   },
   "outputs": [],
   "source": [
    "#Apply sentiment_grouped mapping AFTER filtering\n",
    "df_train[\"sentiment_grouped\"] = df_train[\"sentiment\"].str.lower().str.strip().map(sentiment_map)\n",
    "\n",
    "#  Encode labels from sentiment_grouped\n",
    "label_encode = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df_train[\"label\"] = df_train[\"sentiment_grouped\"].map(label_encode)\n",
    "\n",
    "#print results\n",
    "print(df_train[[\"sentiment\", \"sentiment_grouped\", \"label\"]].head())\n",
    "print(df_train[\"sentiment_grouped\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba3723",
   "metadata": {
    "id": "0bba3723"
   },
   "source": [
    "##### Splitting the dataframe into Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afc7e3",
   "metadata": {
    "id": "47afc7e3"
   },
   "source": [
    "To ensure robust evaluation and prevent information leakage, we divided our dataset into three subsets: a training set, a validation set, and a test set. We used a stratified split based on the sentiment labels to maintain proportional representation of positive, neutral, and negative classes across all subsets. This approach preserves class balance and provides a consistent basis for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e4cd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c04e4cd9",
    "outputId": "f8e48830-8079-4dd9-d9b3-f5d4fb6b98d5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.3,\n",
    "    stratify=df_train[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd9578",
   "metadata": {
    "id": "59dd9578"
   },
   "source": [
    "The resulting split allocates approximately 70% of the data to training and 15% each to validation and testing. Specifically, our dataset was divided into 512 training samples, 110 validation samples, and 110 test samples. The stratification confirmed that each subset contains examples from all sentiment categories, ensuring reliable performance evaluation as we move forward with model training and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da1c3e",
   "metadata": {
    "id": "59da1c3e"
   },
   "source": [
    "Note: A stratified split is a method of dividing your dataset into training, validation, and test sets while preserving the original distribution of the target classes.Each subset (train, validation, test) has the same proportion of each sentiment class as the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec6502",
   "metadata": {
    "id": "31ec6502"
   },
   "source": [
    "#### Convert to HuggingFace Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c403ff9",
   "metadata": {
    "id": "4c403ff9"
   },
   "source": [
    "Before training our Transformer-based sentiment classifier, we convert our pandas DataFrames into HuggingFace Dataset objects. This format is specifically designed for efficient handling of large text datasets, enabling optimized tokenization, batching, and GPU-accelerated training. It also integrates seamlessly with the HuggingFace Trainer API, which we will be later used for fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e41a9",
   "metadata": {
    "id": "206e41a9"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset   = Dataset.from_pandas(val_df)\n",
    "test_dataset  = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cddc9",
   "metadata": {
    "id": "fe1cddc9"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbf859",
   "metadata": {
    "id": "3ffbf859"
   },
   "source": [
    "Transformer models such as DistilBERT cannot read raw text directly. It requires texts to be converted into numerical tokens that represent: words, punctuations, and special model tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4bcde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544,
     "referenced_widgets": [
      "035c546b25614a97a6701cfe5e2adcf2",
      "2023274d69ec4e20a227b6179aa0aae5",
      "286830bbbee74e46b8c21a9beffbee70",
      "2e3b334bf04e46548c401d15f95a31ca",
      "3a6033f8312f4620b1b2a9a0aa31757c",
      "1f59356312b142c2b4e912834ad367fd",
      "780956afe8f8410fa7708931a5d48aec",
      "4877306c53334a86b7dbd1c0d1e13871",
      "2118b776374d4f4f8ce27351ee7897b2",
      "1cd0b58dcb5d4d2388ebcf36a0e85447",
      "ed2c5bced5744974a10b1355e924f414",
      "a6c5cde18d8542a295e8781766bf81be",
      "8cee90a46b8a4232af9158901e2ad648",
      "4ba5c11eb66a47528ff519557ae86c82",
      "48462c1d3a7f48a28d4c41823b0daa42",
      "0a2256730e85408b898c27020964dea2",
      "2d88a2f03e8c4a41a2ad5e90ae803513",
      "62451f08cfbd45c2a04bda5b31578537",
      "bd2d9ff9c9d74fb19c0611c79f318bf9",
      "31e72978ae2d492584685c7f41485c8d",
      "f378ad448c4f454b8ea4d01c52080900",
      "62c0de86ebdc440dbec813c5074c2933",
      "aed86f4f6ff34a0faf391b59d5c664ee",
      "7d00789563a14832aa33371c59593046",
      "bb4843a52a5d4d88a79d831a021bf4ef"
     ]
    },
    "id": "d7b4bcde",
    "outputId": "a5c36bd7-394a-4f4b-9829-1afcac151654"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset  = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a3f47",
   "metadata": {
    "id": "2e3a3f47"
   },
   "source": [
    "Note: What is DistilBERT? It is a distilled (lightweight)version of BERT that has been created by HuggingFace. It is a pre-trained Transformer model which understands the structure of language and the meaning. It knows things like grammar, word relationship, contextual meaning, emotional tone in text and semantics of social media expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d18b24",
   "metadata": {
    "id": "28d18b24"
   },
   "source": [
    "### Rename Column Label properly for HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68e177",
   "metadata": {
    "id": "dd68e177"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset   = val_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset  = test_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373a54f",
   "metadata": {
    "id": "9373a54f"
   },
   "source": [
    "### Remove unnecessary Columns(Keeping only Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a58d02",
   "metadata": {
    "id": "39a58d02"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns([\"text\", \"sentiment\", \"sentiment_grouped\"])\n",
    "val_dataset   = val_dataset.remove_columns([\"text\", \"sentiment\", \"sentiment_grouped\"])\n",
    "test_dataset  = test_dataset.remove_columns([\"text\", \"sentiment\", \"sentiment_grouped\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0cd3d",
   "metadata": {
    "id": "5ef0cd3d"
   },
   "source": [
    "### Training Arguments and Trainer Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731fc77",
   "metadata": {
    "id": "e731fc77"
   },
   "source": [
    "#### Assigning Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ed527",
   "metadata": {
    "id": "007ed527"
   },
   "source": [
    "During the sentiment classification, it was noticed that we have a classes imbalance where we have 472 positive, 177 negatives, 83 negatives. Class weights were applied to address class imbalance by increasing the loss contribution of minority classes. As Neutral posts represented the smallest portion of the dataset, they received the highest weight, ensuring the model learned to classify all sentiment categories more fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eceb97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98eceb97",
    "outputId": "8a33edbe-9a5c-4d3f-db1b-6b8f4170cb16"
   },
   "outputs": [],
   "source": [
    "# Count class distribution after cleaning\n",
    "class_counts = df_train[\"sentiment_grouped\"].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Total number of samples left\n",
    "total_samples = len(df_train)\n",
    "\n",
    "# Calculate weights\n",
    "weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "print(\"\\nUpdated Class Weights:\")\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3778c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22a3778c",
    "outputId": "fcc47bd4-581f-4cb5-9b89-7ea91fa008f5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class_counts = df_train[\"sentiment_grouped\"].value_counts()\n",
    "total_samples = len(df_train)\n",
    "weights_list = [\n",
    "    total_samples / class_counts[\"negative\"],\n",
    "    total_samples / class_counts[\"neutral\"],\n",
    "    total_samples / class_counts[\"positive\"]\n",
    "]\n",
    "class_weights = torch.tensor(weights_list, dtype=torch.float32)\n",
    "\n",
    "print(f\"Final Class Weights tensor (for [Neg, Neut, Pos]): {class_weights}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2c4ca",
   "metadata": {
    "id": "4ee2c4ca"
   },
   "source": [
    "##### Define Custom Weight Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f9c54",
   "metadata": {
    "id": "ac0f9c54"
   },
   "source": [
    "To incorporate our class weights into the training process, we define a custom Trainer that modifies the loss function. The standard HuggingFace Trainer computes an unweighted cross-entropy loss, which treats all classes equally. However, because our dataset is imbalanced—with significantly fewer Neutral and Negative examples—we apply class weighting to increase the penalty for misclassifying minority classes. By customizing the Trainer’s loss computation, we ensure that the model learns to correctly classify all sentiment categories rather than favoring the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630d8c8",
   "metadata": {
    "id": "0630d8c8"
   },
   "source": [
    "The class will ensure that the calculated class_weights are passed to loss function during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f471997",
   "metadata": {
    "id": "0f471997"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs[\"labels\"]\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        weights = self.class_weights.to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991f75b",
   "metadata": {
    "id": "c991f75b"
   },
   "source": [
    "With this custom weighted Trainer implementation, the model will now consider the class distribution during optimization, leading to more balanced learning across Positive, Neutral, and Negative sentiments. This approach helps reduce model bias, improves recall for underrepresented classes, and ultimately leads to a more fair and accurate sentiment classifier. We can now proceed to fine-tune DistilBERT using this custom Trainer setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a52dfe6",
   "metadata": {
    "id": "4a52dfe6"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf28c10",
   "metadata": {
    "id": "cbf28c10"
   },
   "source": [
    "Next, we set up our model and training configuration. The model is initialized with three output labels to match the sentiment categories in our dataset. We also define a set of training parameters that control how the fine-tuning process runs, including the learning rate, number of epochs, and batch sizes for both training and evaluation. Once the configuration is complete, we create our Trainer, which will handle the optimization process and manage the interaction between the model and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6d09e",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bfd6d09e",
    "outputId": "c7ea1b26-0e80-444c-c966-3a9fc5df0a5b"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y7CyN2wh-ZDH",
   "metadata": {
    "id": "Y7CyN2wh-ZDH"
   },
   "source": [
    "Note: Tranformers need to be installed in terminal or using !pip in the notebook for this training to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d480d",
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "58490e04cef2415c83f2a9772709a658",
      "56d142bf0c2242fb91fb82fcc6c37059",
      "240a5724e1b540a68668b9e1c2872077",
      "77fe5bdef18c41ed9272941d5256651e"
     ]
    },
    "id": "5f5d480d",
    "outputId": "a0f38060-59cb-46d2-be96-7e1897df3351"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Convert DataFrames to HuggingFace Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset   = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Tokenizer\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=64,\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Rename column for Trainer compatibility\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset   = val_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove unused text columns\n",
    "cols_to_remove = [\"text\", \"sentiment\", \"sentiment_grouped\"]\n",
    "for col in cols_to_remove:\n",
    "    if col in train_dataset.column_names:\n",
    "        train_dataset = train_dataset.remove_columns(col)\n",
    "    if col in val_dataset.column_names:\n",
    "        val_dataset = val_dataset.remove_columns(col)\n",
    "\n",
    "# Set PyTorch format\n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f008631",
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "9cd8f4b7f11741d486e392760cf94c5e"
     ]
    },
    "id": "7f008631",
    "outputId": "f915db7a-48a9-4a25-a9bc-19599693e700"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# ---- Metrics ----\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# ---- Model ----\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "# ---- Training Arguments ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=6,                # reduced a bit to avoid overfitting\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=30,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# ---- Trainer ----\n",
    "trainer = WeightedTrainer(\n",
    "    class_weights=class_weights,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# ---- Train ----\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc438f9c",
   "metadata": {
    "id": "fc438f9c"
   },
   "source": [
    "With the training process launched, the model begins learning patterns in the text that help distinguish between positive, neutral, and negative sentiment. Over multiple passes through the data, the model adjusts its internal weights to improve prediction accuracy. After training completes, the model will be ready for evaluation on the test set to measure performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b7c75",
   "metadata": {
    "id": "928b7c75"
   },
   "source": [
    "As training progresses, the loss value steadily decreases. Training loss represents how well the model is performing on the training data — lower values indicate that the model’s predictions are becoming more accurate. In the early steps, the model is still learning general patterns in the data, which is why the loss is higher. Over time, as the model adjusts its parameters, the loss reduces significantly, showing that the model is successfully learning to classify sentiment more effectively. The consistent downward trend suggests healthy learning behavior and indicates that the model is improving with each training step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5e3c4",
   "metadata": {
    "id": "38c5e3c4"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e522ae6",
   "metadata": {
    "id": "3e522ae6"
   },
   "source": [
    "##### Create Confusion Matrix + Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d863e",
   "metadata": {
    "id": "960d863e"
   },
   "source": [
    "To evaluate model performance, a confusion matrix and detailed classification metrics were generated using the validation dataset. The results reveal strong predictive performance for clearly emotional content, especially in positive and negative categories, while moderation remains challenging for neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58410444",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "58410444",
    "outputId": "7f57aab4-24b3-4841-9596-689bc8c2c25b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---- Test Predictions ----\n",
    "test_predictions = trainer.predict(val_dataset)\n",
    "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_labels = test_predictions.label_ids\n",
    "\n",
    "# ---- Confusion Matrix ----\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "classes = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes)\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Sentiment Classification\")\n",
    "plt.show()\n",
    "\n",
    "# ---- Classification Report ----\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844198d0",
   "metadata": {
    "id": "844198d0"
   },
   "source": [
    "The sentiment classifier successfully distinguishes strongly emotional content with high precision and minimal sentiment polarity errors, enabling reliable downstream analysis of how sentiment impacts engagement. Attention to neutral sentiment labeling in future dataset expansion will further improve model generalization and fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44999825",
   "metadata": {
    "id": "44999825"
   },
   "source": [
    "Observations show that the model performs very well on positive and negative sentiments with only very few incorrect predictions.  Neutral Sentiment remains the most challenging reflected by:\n",
    "* Few correct predictions (only 6)\n",
    "* Frequent confusion with positive and Negative posts(5 instances)\n",
    "\n",
    "\n",
    "In conclusion, the model does show promising geenralization for the two dominant classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261f319",
   "metadata": {
    "id": "4261f319"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bccce6",
   "metadata": {
    "id": "c4bccce6"
   },
   "source": [
    "The model has been successfully trained, the next step is to evalaute its performance using the following steps:\n",
    "* Use trained model to make predictions on the test dataset\n",
    "* Compare the predicted labels with true labels\n",
    "* Convey predictions in numeric format into readable sentiment categories\n",
    "* Combine everything into a single Dataframe for later analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7890d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ba7890d0",
    "outputId": "4ba351db-6c1e-469f-ec03-ca0abd63bda1"
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(predictions.predictions, axis=1)\n",
    "test_df[\"predicted_label\"] = test_preds\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "test_df[\"predicted_sentiment\"] = test_df[\"predicted_label\"].map(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86518086",
   "metadata": {
    "id": "86518086"
   },
   "source": [
    "#### Evaluate Prediction Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3078dc",
   "metadata": {
    "id": "0e3078dc"
   },
   "source": [
    "After generating predictions from the trained model and converting them into human-readable sentiment labels, we evaluate how well the model performed on unseen data. This involves comparing the predicted sentiment for each post with its actual (ground-truth) sentiment label. By calculating performance metrics such as accuracy, precision, recall, and F1-score—along with visualizing a confusion matrix—we obtain a clear understanding of the model’s strengths and areas for improvement across the three sentiment categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaefd02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eaefd02",
    "outputId": "4efbc62c-c79e-412b-bd22-91fb8edd4ed5"
   },
   "outputs": [],
   "source": [
    "# Count correct predictions for TEST set only\n",
    "correct = (test_df['sentiment_grouped'] == test_df['predicted_sentiment']).sum()\n",
    "total = len(test_df)\n",
    "\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"Correct predictions:\", correct)\n",
    "print(\"Total samples:\", total)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f113747",
   "metadata": {
    "id": "9f113747"
   },
   "source": [
    "We see that the model has a prediction accuracy of about 91%.\n",
    "This means the model is correct more than four out of five times, which reflects solid overall performance. However, accuracy alone does not show where the model struggles, so we will further examine class-specific performance using a confusion matrix and metrics such as precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jUMGPj8y_46i",
   "metadata": {
    "id": "jUMGPj8y_46i"
   },
   "source": [
    "#### To show the rows that were predicted incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aTdYct3OMEMb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTdYct3OMEMb",
    "outputId": "2ba6a6ea-63aa-4b7e-aa39-a5a8d63ced2c"
   },
   "outputs": [],
   "source": [
    "# Filter rows where predictions are wrong\n",
    "wrong_predictions = test_df[test_df['sentiment_grouped'] != test_df['predicted_sentiment']]\n",
    "\n",
    "# Print the text, actual sentiment, and predicted sentiment\n",
    "for index, row in wrong_predictions.iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"Actual Sentiment: {row['sentiment_grouped']}\")\n",
    "    print(f\"Predicted Sentiment: {row['predicted_sentiment']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JdMdWLHDAMsL",
   "metadata": {
    "id": "JdMdWLHDAMsL"
   },
   "source": [
    "From the examples above, we can see that the model struggles with texts that contain ambiguity or figurative language, especially when the emotional tone is subtle or metaphorical. In these cases, the model often misclassifies sentiments—sometimes interpreting negative or neutral expressions as positive, or failing to identify underlying negative cues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2925c",
   "metadata": {
    "id": "16d2925c"
   },
   "source": [
    "#### Create Classification Report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3267f4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3267f4c",
    "outputId": "64dd3cdf-b8e0-496e-a8c1-cc3cfd49324a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "true_labels = test_df['label'].values\n",
    "pred_labels = test_df['predicted_label'].values\n",
    "\n",
    "print(\"\\nCorrect Classification Report:\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=[\"negative\", \"neutral\", \"positive\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fafab6",
   "metadata": {
    "id": "79fafab6"
   },
   "source": [
    "The sentiment classification model achieved strong performance on the test dataset, correctly predicting 91% of unseen social media posts. Positive and negative sentiments were classified with high precision and recall, showing the model can reliably detect strong emotional tone. Neutral sentiment performance was lower, reflecting its subtlety and smaller presence in the training data. Overall, the model demonstrates excellent generalization and is highly effective for real-world sentiment analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301d56d",
   "metadata": {
    "id": "0301d56d"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559c07c",
   "metadata": {
    "id": "c559c07c"
   },
   "source": [
    "To filter the variables of required for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd7370",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "87fd7370",
    "outputId": "51a035d6-5c29-4d3c-fdb1-42d05999d375"
   },
   "outputs": [],
   "source": [
    "clean_df = test_df[\n",
    "    ['text', 'predicted_sentiment', 'likes', 'retweets']\n",
    "]\n",
    "\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c542af5",
   "metadata": {
    "id": "5c542af5"
   },
   "source": [
    "#### Visualization using Bar Charts\n",
    "\n",
    "Before analyzing engagement, it’s important to understand how the model classified the posts across the three sentiment categories. The following step is to see the distribution of predicted sentiments after fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78d93b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "id": "9b78d93b",
    "outputId": "ad121025-80c4-460a-e8c5-e0a3ba435037"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "top_20_sents = clean_df[\"predicted_sentiment\"].value_counts().nlargest(20).index\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "sns.countplot(x=clean_df[\"predicted_sentiment\"], palette='viridis', order=top_20_sents)\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xticks(rotation=45, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I3xCCu1agG_S",
   "metadata": {
    "id": "I3xCCu1agG_S"
   },
   "source": [
    "This chart shows how many posts the model classified into each sentiment category. Most posts are positive, followed by negative, with neutral being the smallest group. This confirms that the classifier successfully assigned sentiments and also highlights the natural imbalance in the dataset, which explains why neutral predictions were more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efec7e9",
   "metadata": {
    "id": "9efec7e9"
   },
   "source": [
    "#### Summary Table\n",
    "\n",
    "This table summarizes the total and average likes and retweets for each sentiment category, showing how engagement levels differ across positive, neutral, and negative posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983b934",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "9983b934",
    "outputId": "f8da3222-64a9-4310-f76b-fc3ea609f5d5"
   },
   "outputs": [],
   "source": [
    "metrics_by_sentiment = (\n",
    "    clean_df\n",
    "    .groupby(\"predicted_sentiment\")\n",
    "    .agg(\n",
    "        likes_Total=(\"likes\", \"sum\"),\n",
    "        likes_Average=(\"likes\", \"mean\"),\n",
    "        retweets_Total=(\"retweets\", \"sum\"),\n",
    "        retweets_Average=(\"retweets\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(metrics_by_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81c1ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "cf81c1ee",
    "outputId": "4cd0985e-17ae-4ff8-999c-8c26de47b9d5"
   },
   "outputs": [],
   "source": [
    "# Rename the sentiment column to match the format you want\n",
    "metrics_avg = metrics_by_sentiment.rename(\n",
    "    columns={\"predicted_sentiment\": \"Sentiment_Category\"}\n",
    ")\n",
    "\n",
    "# Keep only the averages (likes + retweets)\n",
    "metrics_avg = metrics_avg[[\n",
    "    \"Sentiment_Category\",\n",
    "    \"likes_Average\",\n",
    "    \"retweets_Average\"\n",
    "]]\n",
    "\n",
    "# Make sentiment labels consistent (capitalize)\n",
    "metrics_avg[\"Sentiment_Category\"] = (\n",
    "    metrics_avg[\"Sentiment_Category\"].str.capitalize()\n",
    ")\n",
    "\n",
    "# Melt into long format\n",
    "melted_metrics = metrics_avg.melt(\n",
    "    id_vars=\"Sentiment_Category\",\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Average_Value\"\n",
    ")\n",
    "\n",
    "# Clean up metric names: \"likes_Average\" → \"Likes\"\n",
    "melted_metrics[\"Metric\"] = melted_metrics[\"Metric\"].str.replace(\"_Average\", \"\")\n",
    "melted_metrics[\"Metric\"] = melted_metrics[\"Metric\"].str.capitalize()\n",
    "\n",
    "display(melted_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GvBzYnT7gRjZ",
   "metadata": {
    "id": "GvBzYnT7gRjZ"
   },
   "source": [
    "To examine whether sentiment affects engagement, the following step compares the average number of likes and retweets received by posts in each sentiment category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1eb3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "6de1eb3f",
    "outputId": "b89171ac-6ccb-4909-be1d-2eff108f2c0a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Sentiment_Category', y='Average_Value', hue='Metric', data=melted_metrics, palette='viridis')\n",
    "plt.title('Average Likes and Retweets per Sentiment Category')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Average Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cnI0hNgZph",
   "metadata": {
    "id": "27cnI0hNgZph"
   },
   "source": [
    "This chart compares average engagement across sentiment categories. Positive posts receive the highest likes and retweets, neutral posts sit in the middle, and negative posts get the least engagement. This supports the conclusion that sentiment influences engagement, with positive sentiment driving stronger user interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878b70b",
   "metadata": {
    "id": "6878b70b"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98a83f",
   "metadata": {
    "id": "8f98a83f"
   },
   "source": [
    "Finally, we should be able to answer the following question:\n",
    "* Is there a statistically significant relationship between the sentiment expressed in a post and its subsequent level of user engagement?\n",
    "Put another way, \"Do positive posts get more attention(likes/retweets) than neutral or negative posts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac77a76",
   "metadata": {
    "id": "5ac77a76"
   },
   "source": [
    "##### Prepare the data for Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba509c9",
   "metadata": {
    "id": "2ba509c9"
   },
   "source": [
    "To ensure that the likes and retweets column are data type consistent, missing values are handled to ensure they do not offect regression analysis.Missing values are imputed with 0 to ensure that they do not impact the regression analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5357a",
   "metadata": {
    "id": "f7e5357a"
   },
   "outputs": [],
   "source": [
    "full_df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a44165",
   "metadata": {
    "id": "a6a44165"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming your DataFrame is named 'full_df'\n",
    "\n",
    "#Prepare data for regression analysis\n",
    "full_df['likes'] = pd.to_numeric(full_df['likes'], errors='coerce')\n",
    "full_df['retweets'] = pd.to_numeric(full_df['retweets'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0. This ensures that missing data are not treated as an object\n",
    "full_df = full_df.fillna({'likes': 0, 'retweets': 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c51bf",
   "metadata": {
    "id": "891c51bf"
   },
   "source": [
    "To better quantify the impact of each post, we combine likes and retweets into a single response variable—engagement—which represents the total amount of user interaction a post receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc282d",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "44fc282d"
   },
   "outputs": [],
   "source": [
    "# create response variable 'engagement'\n",
    "full_df['engagement'] = full_df['likes'] + full_df['retweets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08caf3",
   "metadata": {
    "id": "9e08caf3",
    "outputId": "0cbc8bb0-6b54-4f61-b11f-17f8c52ccc9e"
   },
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f97f7d",
   "metadata": {
    "id": "58f97f7d"
   },
   "source": [
    "Engagement serves as the response variable in our regression model, allowing us to evaluate whether predicted sentiment influences how much interaction a post generates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc45a8",
   "metadata": {
    "id": "80cc45a8"
   },
   "source": [
    "Regression models — including Ordinary Least Squares (OLS) — can only work with numerical inputs.\n",
    "However, our sentiment predictor variables are categorical meaning they do not have any numerical meaning on their own. So we convert them into dummy variables (also called indicator variables), which turn each category into a separate binary (0 or 1) columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ab5bc",
   "metadata": {
    "id": "6b1ab5bc"
   },
   "source": [
    "To examine how predicted sentiment categories (negative, neutral, positive) influence engagement levels on social media posts.\n",
    "\n",
    "We create dummy variables from the predicted_sentiment column\n",
    "→ negative, neutral, and positive\n",
    "\n",
    "To avoid multicollinearity, we drop neutral as it becomes the baseline/reference group.\n",
    "\n",
    "\n",
    "We run an Ordinary Least Squares (OLS) regression:\n",
    "\n",
    "X = sentiment dummy variables\n",
    "\n",
    "Y = engagement metric\n",
    "\n",
    "Note: In order to avoid the issue of multicollinearity, we cannoy include all three dummy variables and an intercept as the model will be unable to solve such an equation. Hence, a neutral column is dropped in order to allow the model to interpret the remaining coefficients relative to the dropped category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4fede",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "79e4fede",
    "outputId": "21647e18-ae20-4a4d-bdf4-4e3c40295ab9"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Create predictior variables X - using predicted_sentiment\n",
    "# Create dummy variables for predicted_sentiment\n",
    "X_dummies = pd.get_dummies(full_df['sentiment_grouped'], drop_first=False, dtype=int)\n",
    "\n",
    "# Drop the reference group ('neutral') to prevent multicollinearity\n",
    "# Columns in X will be 'negative' and 'positive'\n",
    "X = X_dummies.drop(columns=['neutral'])\n",
    "\n",
    "# Add the constant (intercept) column\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the target variable Y which is engagement (likes + retweets)\n",
    "Y = full_df['engagement']\n",
    "\n",
    "#fit the OLS regression model\n",
    "model = sm.OLS(Y.values, X.values).fit()\n",
    "\n",
    "# Display regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72175098",
   "metadata": {
    "id": "72175098"
   },
   "source": [
    "The regression output shows how engagement changes for negative and positive posts compared to neutral(baseline) posts.\n",
    "\n",
    "* R^2 = 0.110% indicates that only 11.0% of engagement can be explained by sentiment. This indicates that sentiment alone explains only a small portion of engagement behavior, meaning other factors also strongly influence engagement .\n",
    "\n",
    "In the model, Neutral sentiment serves as the reference category. The coefficient for Negative sentiment (x1) is not statistically significant, indicating that negative posts do not differ from neutral posts in engagement. In contrast, Positive sentiment (x2) is statistically significant (p < .001), showing that positive posts generate ~11 more interactions than neutral posts on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20e753",
   "metadata": {
    "id": "1d20e753"
   },
   "source": [
    "### Density of Engagement Across Sentiment Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xA4BaGfI3pV-",
   "metadata": {
    "id": "xA4BaGfI3pV-"
   },
   "source": [
    "To further analyse the distribution of the dataset across the three(3) categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994d303",
   "metadata": {
    "id": "8994d303",
    "outputId": "ca1c5e5c-98dd-4081-c5aa-e246bed0d794"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=full_df,\n",
    "    x='engagement',\n",
    "    hue='sentiment_grouped',\n",
    "    fill=True,\n",
    "    common_norm=False,   # ensures each category has its own density scale\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "plt.title(\"Density Curve of Engagement by Sentiment Category\")\n",
    "plt.xlabel(\"Engagement (likes + retweets)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282c8f4",
   "metadata": {
    "id": "9282c8f4"
   },
   "source": [
    "Positive sentiment appears to be associated with higher engagement, negative sentiment with moderate engagement, and neutral sentiment with the lowest engagement. This observation supports running an OLS regression to formally test whether the relationship between sentiment and engagement is statistically significant.\n",
    "\n",
    "However, the overlapping density curves indicate that engagement levels for some sentiment groups are similar, suggesting that sentiment alone may not fully explain differences in engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e699fb",
   "metadata": {
    "id": "b5e699fb"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b549519",
   "metadata": {
    "id": "9b549519"
   },
   "source": [
    "This project successfully achieved its twin objectives: first, developing a robust deep-learning model for classifying social media sentiment, and second, quantifying the result impact of that sentiment on user engagement.\n",
    "\n",
    "##### Sentiment Classification performance\n",
    "By fine-tuning DistilBERT and implementing a Cross-Entropy Loss strategy to address severe class imbalance especially with our Neutral Sentiment Class, the model achieved high performacne on the validation set with overall accuracy of 92% and weighted F1-Score of 91%.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a2dcc",
   "metadata": {
    "id": "897a2dcc"
   },
   "source": [
    "##### Quantified Impact on Engagement (OLS Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0ec5c",
   "metadata": {
    "id": "e6e0ec5c"
   },
   "source": [
    "The Ordinary Least Square(OLS) regression, which used the predicted sentiment as the primary predictor of post engagement(likes + retweets), yielded the following statistically significant results:\n",
    "* Positive Sentiment is a key Driver: Posts classified as Positive, generate more combined likes and tweers than Neutral Posts. The difference is highly statistically significant.\n",
    "* There does not seem to be a statistically significant difference in engagement between Negative and Neutral Posts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35e60d",
   "metadata": {
    "id": "9f35e60d"
   },
   "source": [
    "##### Project Significance and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066dc3b",
   "metadata": {
    "id": "1066dc3b"
   },
   "source": [
    "This project demonstrates meaningful insights into how sentiment influences social media engagement. The sentiment classifier proved highly effective at detecting strong emotional tone, particularly in positive and negative posts. These capabilities enable practical applications such as monitoring brand perception, boosting content strategy, and improving audience targeting.\n",
    "\n",
    "However, several key limitations should be noted. The dataset included significantly fewer neutral posts, which impacted both model learning and evaluation. Neutral sentiment often contains subtle or ambiguous language, and the small number of examples limited the model’s ability to recognize those nuances. As a result, neutral predictions were less accurate, indicating a need for more balanced training data to improve fairness and generalization. Additionally, attempts were made to incorporate external datasets to increase sample size; however, differences in writing style, platform language, and formatting introduced inconsistencies that would have negatively affected model performance. Ensuring dataset uniformity remains an important factor for maintaining model reliability and generalization.\n",
    "\n",
    "Furthermore, while the regression analysis confirmed that sentiment contributes to engagement behavior, the modest R² value of 0.110 suggests that sentiment alone explains only a small portion of overall interaction levels. Engagement is likely driven by a broader combination of factors—such as posting time, user influence, audience size, media type, and algorithmic visibility —which were not included in this study.\n",
    "\n",
    "Future work should expand the dataset to include more neutral sentiment examples, incorporate richer engagement predictors, and leverage enhanced modeling approaches to better capture subtle emotional signals. Strengthening these areas will improve model robustness and deepen understanding of the complex drivers behind online engagement."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035c546b25614a97a6701cfe5e2adcf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2023274d69ec4e20a227b6179aa0aae5",
       "IPY_MODEL_286830bbbee74e46b8c21a9beffbee70",
       "IPY_MODEL_2e3b334bf04e46548c401d15f95a31ca"
      ],
      "layout": "IPY_MODEL_3a6033f8312f4620b1b2a9a0aa31757c"
     }
    },
    "0a2256730e85408b898c27020964dea2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cd0b58dcb5d4d2388ebcf36a0e85447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f59356312b142c2b4e912834ad367fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2023274d69ec4e20a227b6179aa0aae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f59356312b142c2b4e912834ad367fd",
      "placeholder": "​",
      "style": "IPY_MODEL_780956afe8f8410fa7708931a5d48aec",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "2118b776374d4f4f8ce27351ee7897b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "286830bbbee74e46b8c21a9beffbee70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4877306c53334a86b7dbd1c0d1e13871",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2118b776374d4f4f8ce27351ee7897b2",
      "value": 48
     }
    },
    "2d88a2f03e8c4a41a2ad5e90ae803513": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e3b334bf04e46548c401d15f95a31ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd0b58dcb5d4d2388ebcf36a0e85447",
      "placeholder": "​",
      "style": "IPY_MODEL_ed2c5bced5744974a10b1355e924f414",
      "value": " 48.0/48.0 [00:00&lt;00:00, 3.29kB/s]"
     }
    },
    "31e72978ae2d492584685c7f41485c8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a6033f8312f4620b1b2a9a0aa31757c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48462c1d3a7f48a28d4c41823b0daa42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f378ad448c4f454b8ea4d01c52080900",
      "placeholder": "​",
      "style": "IPY_MODEL_62c0de86ebdc440dbec813c5074c2933",
      "value": " 483/483 [00:00&lt;00:00, 13.5kB/s]"
     }
    },
    "4877306c53334a86b7dbd1c0d1e13871": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba5c11eb66a47528ff519557ae86c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd2d9ff9c9d74fb19c0611c79f318bf9",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31e72978ae2d492584685c7f41485c8d",
      "value": 483
     }
    },
    "62451f08cfbd45c2a04bda5b31578537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62c0de86ebdc440dbec813c5074c2933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "780956afe8f8410fa7708931a5d48aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cee90a46b8a4232af9158901e2ad648": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d88a2f03e8c4a41a2ad5e90ae803513",
      "placeholder": "​",
      "style": "IPY_MODEL_62451f08cfbd45c2a04bda5b31578537",
      "value": "config.json: 100%"
     }
    },
    "a6c5cde18d8542a295e8781766bf81be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cee90a46b8a4232af9158901e2ad648",
       "IPY_MODEL_4ba5c11eb66a47528ff519557ae86c82",
       "IPY_MODEL_48462c1d3a7f48a28d4c41823b0daa42"
      ],
      "layout": "IPY_MODEL_0a2256730e85408b898c27020964dea2"
     }
    },
    "bd2d9ff9c9d74fb19c0611c79f318bf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed2c5bced5744974a10b1355e924f414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f378ad448c4f454b8ea4d01c52080900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
